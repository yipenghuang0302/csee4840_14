\subsection{Custom Functional Units}
In this section we describe the building blocks of the accelerator---our custom functional units---which we assemble to create the submodules described in previous sections. These custom functional units are assembled from IP designs generated by Altera MegaFunctions.

\subsubsection{16-bit Sine and Cosine}
We use Taylor series to estimate sine and cosine functions. The Taylor series expansion for sine is $sin(x) = x - x^3/3! + x^5/5!$... Similarly, the Taylor series expansion for cosine is $cos(x) = 1 - x^2/2! + x^4/4!$... Figures  \ref{fig:sine}, \ref{fig:cosine} show the effect of including more terms on accuracy.

% Figure
\begin{figure}[ht]
\center
\epsfig{figure=../figures/sine.eps,
width=0.5\columnwidth}
\caption{The Taylor series estimate of sine becomes more accurate as more terms are added. Green is the ideal function. Red is the two term estimate and blue is the three term estimate.}
\label{fig:sine}
\end{figure}

% Figure
\begin{figure}[ht]
\center
\epsfig{figure=../figures/cosine.eps,
width=0.5\columnwidth}
\caption{The Taylor series estimate of cosine becomes more accurate as more terms are added. Blue is the ideal function. Green is the two term estimate and red is the three term estimate.}
\label{fig:cosine}
\end{figure}

For our design, we will use just three terms to estimate sine and cosine. This level of accuracy is acceptable because the robot joint angles are constrained to positive and negative one radian. Low order estimates for sine and cosine suffice for function values near the origin.

Such a functional unit would require eight multipliers and would finish in 14 cycles. Specialized multipliers that square a single variable or multiply a variable by a constant coefficient cost less than a regular multiplier, so we use those where possible to trim area costs.

\subsubsection{4x4 Matrix-Matrix Multiplication}
The full transformation matrix pipeline needs to multiply D-H transformation blocks. Instead of instantiating a costly, dedicated 4x4 matrix multiplication functional unit, we use the 6x6 matrix multiplication functional unit needed for the damped least squared algorithm, which would otherwise be idle while the accelerator is finding the Jacobian matrix.

When using the 6x6 matrix multiplier for multiplying 4x4 matrices, the additional pair of rows and columns that pad the 4x4 matrices will be zero.

\subsubsection{6x6 Matrix-Matrix Multiplication}
Matrix-matrix multiplication is highly parallel---multiplying 6x6 matrices requires $6^3$ multiplications that may occur in parallel. We cannot instantiate 216 multipliers on the FPGA, so instead we will do 36 multiplies or 72 multiplies at once.

Strassen's algorithm could further reduce the multiplications needed for 6x6 matrix multiplication.